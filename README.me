**README.txt**

# AI Service with PyTorch and Hugging Face

This repository contains the implementation of an AI service for text classification, utilizing PyTorch and Hugging Face Transformers. The project is integrated with a backend (Express.js) that dynamically configures the scraping URL. The pipeline includes scraping, preprocessing, training, and prediction.

## Folder Structure
```
ai_service/
├── data/                     # Dataset storage
│   ├── scraped_data.csv      # Raw scraped data
│   └── preprocessed_data.csv # Cleaned and processed data
├── src/                      # Source code
│   ├── scraper.py            # Scraping script
│   ├── preprocess.py         # Preprocessing script
│   ├── dataset.py            # Dataset loader
│   ├── model.py              # Model definition
│   ├── train.py              # Training script
│   └── predict.py            # Prediction script
└── requirements.txt          # Dependencies
```

## Setup and Installation

### Prerequisites
- Python 3.8 or higher
- Node.js and npm (for Express.js backend)

### Installation
1. Clone this repository:
   ```bash
   git clone https://github.com/nandaauliaramadhannn/ai_service
   cd ai_service
   ```

2. Create a Python virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate   # On Windows, use `venv\Scripts\activate`
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Start the Express.js backend (refer to `backend.js`):
   ```bash
   node backend.js
   ```

## Usage

### 1. Scraping Data
Run the scraping script to fetch data dynamically based on the configured URL:
```bash
python src/scraper.py
```

### 2. Preprocessing Data
Process the raw data into a clean format:
```bash
python src/preprocess.py
```

### 3. Training the Model
Train the model using the preprocessed dataset:
```bash
python src/train.py
```

### 4. Prediction
Test the model with new input:
```bash
python src/predict.py
```

## Notes
- Ensure the Express.js backend is running and the URL is configured before running `scraper.py`.
- The trained model will be saved as `model.pth` after training.

---

**.gitignore**
```
# Python related
*.pyc
__pycache__/
venv/

# Dataset files
data/*.csv

# Model files
*.pth

# Jupyter Notebooks
.ipynb_checkpoints/

# System files
.DS_Store
Thumbs.db

# Logs and temporary files
*.log
*.tmp
